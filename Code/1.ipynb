{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d25b2b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/ComplexSystemsLab/Rawan/GNN/16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea78797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & Setup -----------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.modules[\"apex\"] = None\n",
    "sys.modules[\"apex.normalization\"] = None\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupShuffleSplit, GroupKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, precision_recall_fscore_support, matthews_corrcoef\n",
    "\n",
    "from tqdm import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "635f9eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# To ensures if we train with the same code and data tomorrow, we get identical results:\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319466fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Labeled Narratives and Scores -------------\n",
    "df = pd.read_csv(\"narratives.csv\")\n",
    "scores_df = pd.read_csv(\"scores.csv\")\n",
    "\n",
    "# ------------------ Drop missing or invalid emotion rows ---\n",
    "df = df[df['Emotion'].notnull()].copy()\n",
    "\n",
    "# --- Lowercase emotion labels -------------\n",
    "df['Emotion'] = df['Emotion'].astype(str).str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb72ba9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['narrative_emotion_encoder.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Encode Emotions -------------\n",
    "emotion_encoder = LabelEncoder()\n",
    "df[\"emotion_label\"] = emotion_encoder.fit_transform(df[\"Emotion\"])\n",
    "joblib.dump(emotion_encoder, \"narrative_emotion_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23349b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load E5 embedder --------\n",
    "embedder = SentenceTransformer(\"intfloat/e5-large-v2\") #note to self: maybe another embeddeR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84905850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Sentence column is string and handle NaN\n",
    "df['Sentence'] = df['Sentence'].astype(str).fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b8729dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc031cf2da3d4934bf6e3c50c70bd8b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/142 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (9068, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Prepare sentences for e5 (instruction-tuned) \n",
    "sentences = [f\"passage: {s}\" for s in df['Sentence'].tolist()]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = embedder.encode(\n",
    "    sentences,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Save embeddings as list in a column\n",
    "df[\"embedding\"] = [emb.tolist() for emb in embeddings]\n",
    "\n",
    "print(\"Embedding shape:\", embeddings.shape)  # (num_sentences, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf532e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Compute Negativity Ratio ---\n",
    "NEGATIVE_EMOTIONS = {\n",
    "    \"disapproval\", \"sadness\", \"anger\", \"grief\", \"fear\", \"disgust\", \"remorse\", \"annoyance\",\n",
    "    \"disappointment\", \"embarrassment\", \"nervousness\", \"confusion\"\n",
    "}\n",
    "\n",
    "negativity_ratio = (\n",
    "    df.groupby([\"Patient\", \"SessionNumber\"])[\"Emotion\"]\n",
    "    .apply(lambda g: g.isin(NEGATIVE_EMOTIONS).sum() / len(g) if len(g) > 0 else 0)\n",
    "    .reset_index(name=\"NegativityRatio\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1ac734b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>SessionNumber</th>\n",
       "      <th>NegativityRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0001</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0002</td>\n",
       "      <td>0.172414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0003</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0004</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0001</td>\n",
       "      <td>S0005</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0011</td>\n",
       "      <td>0.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0012</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0013</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0014</td>\n",
       "      <td>0.702128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0015</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Patient SessionNumber  NegativityRatio\n",
       "0     P0001         S0001         0.028571\n",
       "1     P0001         S0002         0.172414\n",
       "2     P0001         S0003         0.000000\n",
       "3     P0001         S0004         0.200000\n",
       "4     P0001         S0005         0.025000\n",
       "..      ...           ...              ...\n",
       "234   P0014         S0011         0.744681\n",
       "235   P0014         S0012         0.804878\n",
       "236   P0014         S0013         0.738095\n",
       "237   P0014         S0014         0.702128\n",
       "238   P0014         S0015         0.731707\n",
       "\n",
       "[239 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negativity_ratio[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "331729dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient</th>\n",
       "      <th>SessionNumber</th>\n",
       "      <th>NegativityRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0001</td>\n",
       "      <td>0.435897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0002</td>\n",
       "      <td>0.317073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0003</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0004</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0005</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0006</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0007</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0008</td>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0009</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0010</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0011</td>\n",
       "      <td>0.744681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0012</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0013</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0014</td>\n",
       "      <td>0.702128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>P0014</td>\n",
       "      <td>S0015</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient SessionNumber  NegativityRatio\n",
       "0    P0014         S0001         0.435897\n",
       "1    P0014         S0002         0.317073\n",
       "2    P0014         S0003         0.562500\n",
       "3    P0014         S0004         0.847826\n",
       "4    P0014         S0005         0.782609\n",
       "5    P0014         S0006         0.800000\n",
       "6    P0014         S0007         0.789474\n",
       "7    P0014         S0008         0.742857\n",
       "8    P0014         S0009         0.608696\n",
       "9    P0014         S0010         0.767442\n",
       "10   P0014         S0011         0.744681\n",
       "11   P0014         S0012         0.804878\n",
       "12   P0014         S0013         0.738095\n",
       "13   P0014         S0014         0.702128\n",
       "14   P0014         S0015         0.731707"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Filter for Patient 14 ---\n",
    "patient_14_data = df[df[\"Patient\"] == \"P0014\"]\n",
    "\n",
    "# --- Compute Negativity Ratio for Patient 14 only ---\n",
    "negativity_ratio_p14 = (\n",
    "    patient_14_data.groupby([\"Patient\", \"SessionNumber\"])[\"Emotion\"]\n",
    "    .apply(lambda g: g.isin(NEGATIVE_EMOTIONS).sum() / len(g) if len(g) > 0 else 0)\n",
    "    .reset_index(name=\"NegativityRatio\")\n",
    ")\n",
    "\n",
    "negativity_ratio_p14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef352d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Merge Session Scores + Label Session Status ---\n",
    "session_status = scores_df.merge(negativity_ratio, on=[\"Patient\", \"SessionNumber\"], how=\"left\")\n",
    "\n",
    "def classify_session(row):\n",
    "    if row[\"NegativityRatio\"] < 0.2 and row[\"GAD-7_Score\"] <= 10 and row[\"PHQ-9_Score\"] <= 10:\n",
    "        return \"Improving\"\n",
    "    elif row[\"NegativityRatio\"] > 0.6 and (row[\"GAD-7_Score\"] > 15 or row[\"PHQ-9_Score\"] > 15):\n",
    "        return \"Deteriorating\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "session_status[\"SessionStatus\"] = session_status.apply(classify_session, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e91db29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['session_status_encoder.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_encoder = LabelEncoder()\n",
    "\n",
    "session_status[\"SessionStatusLabel\"] = status_encoder.fit_transform(session_status[\"SessionStatus\"])\n",
    "joblib.dump(status_encoder, \"session_status_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Merge Status Info into Main Data -----==\n",
    "df = df.merge(\n",
    "    session_status[[\"Patient\", \"SessionNumber\", \"SessionStatus\", \"SessionStatusLabel\"]],\n",
    "    on=[\"Patient\", \"SessionNumber\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421e8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique emotions: 26\n",
      "Encoded classes: 26\n",
      "Example emotions: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'joy', 'love', 'nervousness', 'neutral', 'optimism', 'pride', 'realization', 'remorse', 'sadness', 'surprise']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique emotions:\", df[\"Emotion\"].nunique())\n",
    "print(\"Encoded classes:\", len(emotion_encoder.classes_))\n",
    "print(\"Example emotions:\", list(emotion_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862172db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphs created: 239\n"
     ]
    }
   ],
   "source": [
    "# --- Build Therapy Graphs (temporal edges only) --------\n",
    "therapy_graphs = []\n",
    "session_meta = []   # to support grouped/stratified splitting . . . \n",
    "\n",
    "for (patient, session), group in df.groupby([\"Patient\", \"SessionNumber\"]):\n",
    "    if len(group) < 2:\n",
    "        continue  # tp skip too-short sessions\n",
    "\n",
    "    x = torch.tensor(np.stack(group[\"embedding\"].values), dtype=torch.float)\n",
    "    y_node = torch.tensor(group[\"emotion_label\"].values, dtype=torch.long)\n",
    "    y_graph = torch.tensor([group[\"SessionStatusLabel\"].iloc[0]], dtype=torch.long)\n",
    "\n",
    "    # temporal bidirectional chain (Prev/next nodes) .... \n",
    "    edge_index = torch.tensor(\n",
    "        [[i, i + 1] for i in range(len(group) - 1)] + [[i + 1, i] for i in range(len(group) - 1)],\n",
    "        dtype=torch.long\n",
    "    ).T\n",
    "\n",
    "    sid = f\"{patient}_{session}\"\n",
    "    graph = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        y=y_node,\n",
    "        graph_label=y_graph,\n",
    "        session_id=sid,\n",
    "        patient_id=str(patient)  # keep as string for grouping \n",
    "    )\n",
    "    therapy_graphs.append(graph)\n",
    "    session_meta.append({\n",
    "        \"session_id\": sid,\n",
    "        \"patient\": str(patient),\n",
    "        \"status_label\": int(y_graph.item())\n",
    "    })\n",
    "\n",
    "print(f\"Graphs created: {len(therapy_graphs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SessionStatus label counts (all):\n",
      "status_label\n",
      "0     14\n",
      "1      9\n",
      "2    216\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ------------- Session-level dataframe for splits ---\n",
    "meta_df = pd.DataFrame(session_meta)\n",
    "print(\"SessionStatus label counts (all):\")\n",
    "print(meta_df[\"status_label\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb9abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected test fraction ≈ 0.16 (target 0.15), via StratifiedGroupKFold(n_splits=3)\n"
     ]
    }
   ],
   "source": [
    "sid_to_idx = {g.session_id: i for i, g in enumerate(therapy_graphs)}\n",
    "\n",
    "target_test_frac = 0.15\n",
    "n_splits_candidates = list(range(3, 11))\n",
    "best = dict(gap=1e9, fold=None, n_splits=None, frac=None)\n",
    "\n",
    "for n_splits in n_splits_candidates:\n",
    "    try:\n",
    "        sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "        for train_idx_tmp, test_idx_tmp in sgkf.split(\n",
    "            meta_df.index,\n",
    "            y=meta_df[\"status_label\"],\n",
    "            groups=meta_df[\"patient\"]\n",
    "        ):\n",
    "            frac = len(test_idx_tmp) / len(meta_df)\n",
    "            gap = abs(frac - target_test_frac)\n",
    "            if gap < best[\"gap\"]:\n",
    "                best.update(gap=gap, fold=(train_idx_tmp, test_idx_tmp), n_splits=n_splits, frac=frac)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "if best[\"fold\"] is None:\n",
    "    raise RuntimeError(\n",
    "        \"Could not find a valid grouped+stratified split. \"\n",
    "        \"Consider relaxing the target fraction or adding more data.\"\n",
    "    )\n",
    "\n",
    "train_pool_idx, test_idx = best[\"fold\"]\n",
    "print(\n",
    "    f\"Selected test fraction ≈ {best['frac']:.2f} \"\n",
    "    f\"(target {target_test_frac}), via StratifiedGroupKFold(n_splits={best['n_splits']})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b14f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST sessions: 38 | status dist:\n",
      "status_label\n",
      "0     2.6%\n",
      "1    18.4%\n",
      "2    78.9%\n",
      "Name: proportion, dtype: object\n",
      "CV-POOL sessions: 201 | status dist:\n",
      "status_label\n",
      "0     6.5%\n",
      "1     1.0%\n",
      "2    92.5%\n",
      "Name: proportion, dtype: object\n",
      "Using GroupKFold with n_splits=10 (unique patients in CV pool: 11)\n",
      "Fold 1: train=136 val=65\n",
      "Fold 2: train=186 val=15\n",
      "Fold 3: train=186 val=15\n",
      "Fold 4: train=186 val=15\n",
      "Fold 5: train=186 val=15\n",
      "Fold 6: train=186 val=15\n",
      "Fold 7: train=186 val=15\n",
      "Fold 8: train=186 val=15\n",
      "Fold 9: train=186 val=15\n",
      "Fold 10: train=185 val=16\n"
     ]
    }
   ],
   "source": [
    "test_sessions = meta_df.iloc[test_idx][\"session_id\"].tolist()\n",
    "cv_sessions = meta_df.iloc[train_pool_idx][\"session_id\"].tolist()\n",
    "\n",
    "test_graphs = [therapy_graphs[sid_to_idx[sid]] for sid in test_sessions]\n",
    "cv_graphs = [therapy_graphs[sid_to_idx[sid]] for sid in cv_sessions]\n",
    "\n",
    "def show_dist(tag, subset_sessions):\n",
    "    sub = meta_df.set_index(\"session_id\").loc[subset_sessions]\n",
    "    counts = sub[\"status_label\"].value_counts(normalize=True).sort_index()\n",
    "    print(f\"{tag} sessions: {len(subset_sessions)} | status dist:\")\n",
    "    print((counts * 100).round(1).astype(str) + \"%\")\n",
    "\n",
    "show_dist(\"TEST\", test_sessions)\n",
    "show_dist(\"CV-POOL\", cv_sessions)\n",
    "\n",
    "cv_meta = meta_df.set_index(\"session_id\").loc[cv_sessions].reset_index(drop=False)\n",
    "cv_groups = cv_meta[\"patient\"].values\n",
    "\n",
    "unique_groups = np.unique(cv_groups)\n",
    "n_groups = len(unique_groups)\n",
    "n_splits_cv = min(10, n_groups)  # cap at 10, but not more than available patients\n",
    "\n",
    "if n_splits_cv < 2:\n",
    "    raise ValueError(\n",
    "        f\"Not enough distinct patients in CV pool for GroupKFold. \"\n",
    "        f\"Found {n_groups} group(s). Consider reducing test size or adding data.\"\n",
    "    )\n",
    "\n",
    "print(f\"Using GroupKFold with n_splits={n_splits_cv} (unique patients in CV pool: {n_groups})\")\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_splits_cv)\n",
    "\n",
    "cv_folds = []\n",
    "for fold, (tr_idx, va_idx) in enumerate(gkf.split(cv_meta.index, groups=cv_groups), start=1):\n",
    "    train_sids = cv_meta.iloc[tr_idx][\"session_id\"].tolist()\n",
    "    val_sids   = cv_meta.iloc[va_idx][\"session_id\"].tolist()\n",
    "    cv_folds.append((train_sids, val_sids))\n",
    "    print(f\"Fold {fold}: train={len(train_sids)} val={len(val_sids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce2cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature dim after adding positional feature: 1025\n"
     ]
    }
   ],
   "source": [
    "def add_positional_feature_to_graph(g: Data) -> Data:\n",
    "    n = g.x.size(0)\n",
    "    if n == 1:\n",
    "        pos = torch.tensor([[0.0]], dtype=torch.float, device=g.x.device)\n",
    "    else:\n",
    "        pos_vals = torch.arange(n, dtype=torch.float, device=g.x.device) / max(1, (n - 1))\n",
    "        pos = pos_vals.view(-1, 1)\n",
    "    if g.x.size(1) == 1024:  # raw E5 dims\n",
    "        g.x = torch.cat([g.x, pos], dim=1)  # -> 1025 dims\n",
    "    return g\n",
    "\n",
    "for g in therapy_graphs:\n",
    "    add_positional_feature_to_graph(g)\n",
    "\n",
    "input_dim = therapy_graphs[0].x.size(1)\n",
    "print(f\"Node feature dim after adding positional feature: {input_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5516a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---== 2-layer GATv2 + LayerNorm + dropout --------\n",
    "from torch_geometric.nn import GATv2Conv, GlobalAttention\n",
    "\n",
    "class GATv2MultiTask_Small(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_node_classes, num_graph_classes, heads=2, dropout=0.35):\n",
    "        super().__init__()\n",
    "        self.dropout_p = dropout\n",
    "\n",
    "        self.gat1 = GATv2Conv(input_dim, hidden_dim, heads=heads, dropout=dropout)\n",
    "        self.ln1  = nn.LayerNorm(hidden_dim * heads)\n",
    "\n",
    "        self.gat2 = GATv2Conv(hidden_dim * heads, hidden_dim, heads=1, dropout=dropout)\n",
    "        self.ln2  = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        self.global_attention = GlobalAttention(\n",
    "            gate_nn=nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, 1)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.node_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_node_classes)\n",
    "        )\n",
    "\n",
    "        self.graph_classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 2, num_graph_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = self.gat1(x, edge_index); x = self.ln1(x); x = F.elu(x)\n",
    "        x = self.gat2(x, edge_index); x = self.ln2(x); x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        node_out = self.node_classifier(x)\n",
    "        graph_emb = self.global_attention(x, batch)\n",
    "        graph_out = self.graph_classifier(graph_emb)\n",
    "        return node_out, graph_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -======-- Utilities: loaders, softened class weights, losses, evaluation ---\n",
    "def make_loaders_from_session_ids(train_sids, val_sids, batch_size=8):\n",
    "    train_graphs = [therapy_graphs[sid_to_idx[sid]] for sid in train_sids]\n",
    "    val_graphs   = [therapy_graphs[sid_to_idx[sid]] for sid in val_sids]\n",
    "    train_loader = DataLoader(train_graphs, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_graphs, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def compute_class_weights_for_fold(train_sids, num_node_classes, num_graph_classes, eps=1e-6,\n",
    "                                   min_w=0.5, max_w=2.0):\n",
    "    # Node-level counts\n",
    "    node_counts = np.zeros(num_node_classes, dtype=np.float64)\n",
    "    # Graph-level counts\n",
    "    graph_counts = np.zeros(num_graph_classes, dtype=np.float64)\n",
    "\n",
    "    for sid in train_sids:\n",
    "        g = therapy_graphs[sid_to_idx[sid]]\n",
    "        y_nodes = g.y.cpu().numpy()\n",
    "        for c in y_nodes:\n",
    "            node_counts[int(c)] += 1.0\n",
    "        graph_counts[int(g.graph_label.item())] += 1.0\n",
    "\n",
    "    inv_node = np.zeros_like(node_counts, dtype=np.float64)\n",
    "    mask_nz = node_counts > 0\n",
    "    inv_node[mask_nz] = 1.0 / node_counts[mask_nz]\n",
    "    if (~mask_nz).any():\n",
    "        fill_val = np.median(inv_node[mask_nz]) if mask_nz.any() else 1.0\n",
    "        inv_node[~mask_nz] = fill_val\n",
    "\n",
    "    inv_graph = np.zeros_like(graph_counts, dtype=np.float64)\n",
    "    mask_gz = graph_counts > 0\n",
    "    inv_graph[mask_gz] = 1.0 / graph_counts[mask_gz]\n",
    "    if (~mask_gz).any():\n",
    "        fill_val_g = np.median(inv_graph[mask_gz]) if mask_gz.any() else 1.0\n",
    "        inv_graph[~mask_gz] = fill_val_g\n",
    "\n",
    "    node_weights = inv_node / inv_node.sum() * num_node_classes\n",
    "    graph_weights = inv_graph / inv_graph.sum() * num_graph_classes\n",
    "\n",
    "    node_weights = np.clip(node_weights, min_w, max_w)\n",
    "    graph_weights = np.clip(graph_weights, min_w, max_w)\n",
    "\n",
    "    node_weights_t = torch.tensor(node_weights, dtype=torch.float, device=device)\n",
    "    graph_weights_t = torch.tensor(graph_weights, dtype=torch.float, device=device)\n",
    "    return node_weights_t, graph_weights_t\n",
    "\n",
    "\n",
    "def maybe_augment_x(x, sigma=0.01, p=0.5):\n",
    "    if sigma <= 0 or p <= 0:\n",
    "        return x\n",
    "    if torch.rand(1, device=x.device).item() < p:\n",
    "        return x + torch.randn_like(x) * sigma\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8ca04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_epoch(model, loader, loss_node_fn, loss_graph_fn, lambda_node: float, lambda_graph: float):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_node_preds, all_node_labels = [], []\n",
    "    all_graph_preds, all_graph_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "            node_out, graph_out = model(batch.x, batch.edge_index, batch.batch)\n",
    "\n",
    "            loss_n = loss_node_fn(node_out, batch.y)\n",
    "            loss_g = loss_graph_fn(graph_out, batch.graph_label)\n",
    "            loss = lambda_node * loss_n + lambda_graph * loss_g\n",
    "            total_loss += float(loss.item())\n",
    "\n",
    "            all_node_preds.extend(node_out.argmax(dim=1).detach().cpu().tolist())\n",
    "            all_node_labels.extend(batch.y.detach().cpu().tolist())\n",
    "            all_graph_preds.extend(graph_out.argmax(dim=1).detach().cpu().tolist())\n",
    "            all_graph_labels.extend(batch.graph_label.detach().cpu().tolist())\n",
    "\n",
    "    avg_loss = total_loss / max(1, len(loader))\n",
    "    node_acc = accuracy_score(all_node_labels, all_node_preds) if all_node_labels else 0.0\n",
    "    graph_acc = accuracy_score(all_graph_labels, all_graph_preds) if all_graph_labels else 0.0\n",
    "    node_f1 = f1_score(all_node_labels, all_node_preds, average=\"macro\", zero_division=0) if all_node_labels else 0.0\n",
    "    graph_f1 = f1_score(all_graph_labels, all_graph_preds, average=\"macro\", zero_division=0) if all_graph_labels else 0.0\n",
    "\n",
    "    return {\n",
    "        \"loss\": avg_loss,\n",
    "        \"node_acc\": node_acc, \"node_f1\": node_f1,\n",
    "        \"graph_acc\": graph_acc, \"graph_f1\": graph_f1,\n",
    "        \"node_preds\": all_node_preds, \"node_labels\": all_node_labels,\n",
    "        \"graph_preds\": all_graph_preds, \"graph_labels\": all_graph_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9f313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss balance config: λ_graph=1.0, λ_node_start=0.8, λ_node_end=0.5, anneal_start_frac=0.4, strategy=linear\n"
     ]
    }
   ],
   "source": [
    "# -------- Training Hyperparametersss ---\n",
    "num_node_classes  = len(emotion_encoder.classes_)\n",
    "num_graph_classes = len(status_encoder.classes_)\n",
    "\n",
    "EPOCHS = 200          \n",
    "BATCH_SIZE = 8\n",
    "PATIENCE = 30         \n",
    "LR = 1e-4            \n",
    "WEIGHT_DECAY = 5e-4  \n",
    "HEADS = 2\n",
    "HIDDEN = 64\n",
    "DROPOUT = 0.35\n",
    "\n",
    "LAMBDA_GRAPH = 1.0\n",
    "LAMBDA_NODE_START = 0.8   \n",
    "LAMBDA_NODE_END   = 0.5\n",
    "ANNEAL_START_FRAC = 0.40\n",
    "ANNEAL_STRATEGY   = \"linear\"\n",
    "\n",
    "print(\n",
    "    \"Loss balance config: \"\n",
    "    f\"λ_graph={LAMBDA_GRAPH}, λ_node_start={LAMBDA_NODE_START}, \"\n",
    "    f\"λ_node_end={LAMBDA_NODE_END}, anneal_start_frac={ANNEAL_START_FRAC}, \"\n",
    "    f\"strategy={ANNEAL_STRATEGY}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad2671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Fold 1/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done. Best ValLoss=1.2261 | Val Node Acc=37.3% | Val Graph Acc=100.0%\n",
      "Saved best model for fold 1: gnn_multitask_best_fold1.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              0.00    0.00    0.00    0.00  -0.009       49\n",
      "amusement               0.00    0.00    0.00    0.00  -0.005       12\n",
      "anger                   0.00    0.00    0.00    0.00  -0.002        5\n",
      "annoyance               0.00    0.00    0.00    0.00  -0.004       42\n",
      "approval               67.82   28.92   67.82   40.55   0.337      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity              66.67   14.81   66.67   24.24   0.309        6\n",
      "desire                  5.94   40.00    5.94   10.34   0.134      101\n",
      "disappointment         54.48   35.27   54.48   42.82   0.367      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment          50.00  100.00   50.00   66.67   0.707        2\n",
      "excitement             16.67   21.74   16.67   18.87   0.177       30\n",
      "fear                   41.94   47.27   41.94   44.44   0.424       62\n",
      "gratitude              64.29   47.37   64.29   54.55   0.542       28\n",
      "joy                    20.00   27.14   20.00   23.03   0.191       95\n",
      "love                   58.67   51.76   58.67   55.00   0.527       75\n",
      "nervousness            21.82   44.44   21.82   29.27   0.295       55\n",
      "neutral                42.98   30.51   42.98   35.69   0.225      235\n",
      "optimism                3.28   66.67    3.28    6.25   0.142       61\n",
      "pride                  67.86   40.43   67.86   50.67   0.513       28\n",
      "realization            28.43   37.18   28.43   32.22   0.285      102\n",
      "remorse                 0.00    0.00    0.00    0.00  -0.003       20\n",
      "sadness                35.51   40.16   35.51   37.69   0.322      138\n",
      "surprise                2.78   33.33    2.78    5.13   0.091       36\n",
      "\n",
      "Overall accuracy: 33.93%\n",
      "Overall MCC: 0.278\n",
      "\n",
      "========== Fold 2/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 31\n",
      "Fold 2 done. Best ValLoss=3.9822 | Val Node Acc=29.9% | Val Graph Acc=20.0%\n",
      "Saved best model for fold 2: gnn_multitask_best_fold2.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              2.04    1.79    2.04    1.90  -0.015       49\n",
      "amusement               0.00    0.00    0.00    0.00   0.000       12\n",
      "anger                   0.00    0.00    0.00    0.00   0.000        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval                1.72   30.00    1.72    3.26   0.048      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity              16.67    0.53   16.67    1.02   0.009        6\n",
      "desire                  0.00    0.00    0.00    0.00   0.000      101\n",
      "disappointment          0.00    0.00    0.00    0.00   0.000      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment           0.00    0.00    0.00    0.00   0.000        2\n",
      "excitement              0.00    0.00    0.00    0.00  -0.004       30\n",
      "fear                   64.52    5.55   64.52   10.22   0.076       62\n",
      "gratitude               0.00    0.00    0.00    0.00   0.000       28\n",
      "joy                    33.68    5.40   33.68    9.30  -0.021       95\n",
      "love                    0.00    0.00    0.00    0.00   0.000       75\n",
      "nervousness             0.00    0.00    0.00    0.00   0.000       55\n",
      "neutral                 0.00    0.00    0.00    0.00   0.000      235\n",
      "optimism                0.00    0.00    0.00    0.00   0.000       61\n",
      "pride                   0.00    0.00    0.00    0.00   0.000       28\n",
      "realization             0.00    0.00    0.00    0.00   0.000      102\n",
      "remorse                 0.00    0.00    0.00    0.00   0.000       20\n",
      "sadness                 0.00    0.00    0.00    0.00   0.000      138\n",
      "surprise                0.00    0.00    0.00    0.00   0.000       36\n",
      "\n",
      "Overall accuracy: 4.90%\n",
      "Overall MCC: 0.008\n",
      "\n",
      "========== Fold 3/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done. Best ValLoss=1.2699 | Val Node Acc=34.8% | Val Graph Acc=100.0%\n",
      "Saved best model for fold 3: gnn_multitask_best_fold3.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              2.04    8.33    2.04    3.28   0.026       49\n",
      "amusement              16.67  100.00   16.67   28.57   0.407       12\n",
      "anger                   0.00    0.00    0.00    0.00  -0.002        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               54.02   31.02   54.02   39.41   0.311      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity              16.67   25.00   16.67   20.00   0.202        6\n",
      "desire                 10.89   55.00   10.89   18.18   0.225      101\n",
      "disappointment         54.48   34.50   54.48   42.25   0.361      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment           0.00    0.00    0.00    0.00  -0.001        2\n",
      "excitement             16.67   15.15   16.67   15.87   0.142       30\n",
      "fear                   53.23   32.67   53.23   40.49   0.387       62\n",
      "gratitude              60.71   56.67   60.71   58.62   0.579       28\n",
      "joy                     8.42   25.00    8.42   12.60   0.115       95\n",
      "love                   61.33   46.94   61.33   53.18   0.510       75\n",
      "nervousness             0.00    0.00    0.00    0.00   0.000       55\n",
      "neutral                48.94   32.39   48.94   38.98   0.264      235\n",
      "optimism                9.84   50.00    9.84   16.44   0.209       61\n",
      "pride                  85.71   29.63   85.71   44.04   0.491       28\n",
      "realization            36.27   34.91   36.27   35.58   0.310      102\n",
      "remorse                20.00   26.67   20.00   22.86   0.222       20\n",
      "sadness                42.75   44.70   42.75   43.70   0.384      138\n",
      "surprise                5.56   66.67    5.56   10.26   0.188       36\n",
      "\n",
      "Overall accuracy: 34.63%\n",
      "Overall MCC: 0.286\n",
      "\n",
      "========== Fold 4/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done. Best ValLoss=1.2144 | Val Node Acc=32.9% | Val Graph Acc=100.0%\n",
      "Saved best model for fold 4: gnn_multitask_best_fold4.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              4.08   22.22    4.08    6.90   0.083       49\n",
      "amusement              33.33   50.00   33.33   40.00   0.405       12\n",
      "anger                   0.00    0.00    0.00    0.00  -0.003        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               60.92   27.18   60.92   37.59   0.295      174\n",
      "caring                  0.00    0.00    0.00    0.00  -0.006       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity               0.00    0.00    0.00    0.00  -0.005        6\n",
      "desire                  1.98   33.33    1.98    3.74   0.068      101\n",
      "disappointment         59.31   32.21   59.31   41.75   0.359      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment          50.00   50.00   50.00   50.00   0.499        2\n",
      "excitement             26.67   26.67   26.67   26.67   0.252       30\n",
      "fear                   51.61   33.68   51.61   40.76   0.387       62\n",
      "gratitude              42.86   70.59   42.86   53.33   0.544       28\n",
      "joy                    14.74   26.92   14.74   19.05   0.162       95\n",
      "love                   44.00   57.89   44.00   50.00   0.483       75\n",
      "nervousness             1.82   50.00    1.82    3.51   0.090       55\n",
      "neutral                42.13   28.95   42.13   34.32   0.207      235\n",
      "optimism                1.64   12.50    1.64    2.90   0.032       61\n",
      "pride                  82.14   29.49   82.14   43.40   0.479       28\n",
      "realization            32.35   34.02   32.35   33.17   0.287      102\n",
      "remorse                20.00   36.36   20.00   25.81   0.263       20\n",
      "sadness                27.54   45.24   27.54   34.23   0.306      138\n",
      "surprise                0.00    0.00    0.00    0.00   0.000       36\n",
      "\n",
      "Overall accuracy: 31.76%\n",
      "Overall MCC: 0.254\n",
      "\n",
      "========== Fold 5/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 84\n",
      "Fold 5 done. Best ValLoss=2.3573 | Val Node Acc=28.5% | Val Graph Acc=93.3%\n",
      "Saved best model for fold 5: gnn_multitask_best_fold5.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              0.00    0.00    0.00    0.00   0.000       49\n",
      "amusement               0.00    0.00    0.00    0.00  -0.005       12\n",
      "anger                   0.00    0.00    0.00    0.00   0.000        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               74.71   20.19   74.71   31.78   0.242      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity               0.00    0.00    0.00    0.00  -0.002        6\n",
      "desire                  0.00    0.00    0.00    0.00   0.000      101\n",
      "disappointment         67.59   24.56   67.59   36.03   0.309      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment           0.00    0.00    0.00    0.00  -0.001        2\n",
      "excitement             16.67   26.32   16.67   20.41   0.197       30\n",
      "fear                    1.61   25.00    1.61    3.03   0.055       62\n",
      "gratitude               0.00    0.00    0.00    0.00  -0.003       28\n",
      "joy                     1.05   33.33    1.05    2.04   0.050       95\n",
      "love                    0.00    0.00    0.00    0.00   0.000       75\n",
      "nervousness             0.00    0.00    0.00    0.00   0.000       55\n",
      "neutral                43.83   27.84   43.83   34.05   0.200      235\n",
      "optimism                0.00    0.00    0.00    0.00   0.000       61\n",
      "pride                   0.00    0.00    0.00    0.00  -0.003       28\n",
      "realization            11.76   46.15   11.76   18.75   0.209      102\n",
      "remorse                 0.00    0.00    0.00    0.00   0.000       20\n",
      "sadness                26.81   38.95   26.81   31.76   0.270      138\n",
      "surprise                0.00    0.00    0.00    0.00   0.000       36\n",
      "\n",
      "Overall accuracy: 24.63%\n",
      "Overall MCC: 0.167\n",
      "\n",
      "========== Fold 6/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 55\n",
      "Fold 6 done. Best ValLoss=2.5065 | Val Node Acc=26.9% | Val Graph Acc=80.0%\n",
      "Saved best model for fold 6: gnn_multitask_best_fold6.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              0.00    0.00    0.00    0.00   0.000       49\n",
      "amusement               0.00    0.00    0.00    0.00   0.000       12\n",
      "anger                   0.00    0.00    0.00    0.00   0.000        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               70.11   20.37   70.11   31.57   0.232      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity               0.00    0.00    0.00    0.00   0.000        6\n",
      "desire                  0.00    0.00    0.00    0.00   0.000      101\n",
      "disappointment         49.66   32.00   49.66   38.92   0.322      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment           0.00    0.00    0.00    0.00   0.000        2\n",
      "excitement              0.00    0.00    0.00    0.00   0.000       30\n",
      "fear                    0.00    0.00    0.00    0.00   0.000       62\n",
      "gratitude               0.00    0.00    0.00    0.00   0.000       28\n",
      "joy                     0.00    0.00    0.00    0.00   0.000       95\n",
      "love                    0.00    0.00    0.00    0.00   0.000       75\n",
      "nervousness             0.00    0.00    0.00    0.00   0.000       55\n",
      "neutral                53.62   19.78   53.62   28.90   0.112      235\n",
      "optimism                0.00    0.00    0.00    0.00   0.000       61\n",
      "pride                   0.00    0.00    0.00    0.00   0.000       28\n",
      "realization            12.75   12.15   12.75   12.44   0.062      102\n",
      "remorse                 0.00    0.00    0.00    0.00   0.000       20\n",
      "sadness                 0.00    0.00    0.00    0.00  -0.014      138\n",
      "surprise                0.00    0.00    0.00    0.00   0.000       36\n",
      "\n",
      "Overall accuracy: 21.20%\n",
      "Overall MCC: 0.116\n",
      "\n",
      "========== Fold 7/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done. Best ValLoss=1.3148 | Val Node Acc=28.8% | Val Graph Acc=100.0%\n",
      "Saved best model for fold 7: gnn_multitask_best_fold7.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              6.12    7.89    6.12    6.90   0.043       49\n",
      "amusement               0.00    0.00    0.00    0.00   0.000       12\n",
      "anger                   0.00    0.00    0.00    0.00   0.000        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               60.92   28.57   60.92   38.90   0.310      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity              16.67   14.29   16.67   15.38   0.151        6\n",
      "desire                  4.95   50.00    4.95    9.01   0.142      101\n",
      "disappointment         68.97   32.89   68.97   44.54   0.400      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment          50.00  100.00   50.00   66.67   0.707        2\n",
      "excitement             23.33   46.67   23.33   31.11   0.321       30\n",
      "fear                   45.16   46.67   45.16   45.90   0.437       62\n",
      "gratitude              17.86   41.67   17.86   25.00   0.264       28\n",
      "joy                    18.95   37.50   18.95   25.17   0.234       95\n",
      "love                   33.33   59.52   33.33   42.74   0.426       75\n",
      "nervousness             9.09   62.50    9.09   15.87   0.230       55\n",
      "neutral                48.51   30.32   48.51   37.32   0.242      235\n",
      "optimism               24.59   34.09   24.59   28.57   0.265       61\n",
      "pride                  78.57   32.35   78.57   45.83   0.491       28\n",
      "realization            26.47   37.50   26.47   31.03   0.276      102\n",
      "remorse                30.00   54.55   30.00   38.71   0.399       20\n",
      "sadness                28.26   46.99   28.26   35.29   0.319      138\n",
      "surprise                0.00    0.00    0.00    0.00  -0.004       36\n",
      "\n",
      "Overall accuracy: 33.55%\n",
      "Overall MCC: 0.272\n",
      "\n",
      "========== Fold 8/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done. Best ValLoss=1.3149 | Val Node Acc=29.1% | Val Graph Acc=100.0%\n",
      "Saved best model for fold 8: gnn_multitask_best_fold8.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              2.04   20.00    2.04    3.70   0.055       49\n",
      "amusement               0.00    0.00    0.00    0.00  -0.004       12\n",
      "anger                   0.00    0.00    0.00    0.00   0.000        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               58.62   25.95   58.62   35.98   0.274      174\n",
      "caring                  3.03   50.00    3.03    5.71   0.119       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity               0.00    0.00    0.00    0.00   0.000        6\n",
      "desire                  6.93   38.89    6.93   11.76   0.142      101\n",
      "disappointment         48.97   33.49   48.97   39.78   0.331      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment           0.00    0.00    0.00    0.00   0.000        2\n",
      "excitement             23.33   29.17   23.33   25.93   0.248       30\n",
      "fear                   38.71   46.15   38.71   42.11   0.401       62\n",
      "gratitude              57.14   41.03   57.14   47.76   0.473       28\n",
      "joy                    16.84   30.77   16.84   21.77   0.192       95\n",
      "love                    1.33   33.33    1.33    2.56   0.059       75\n",
      "nervousness            20.00   52.38   20.00   28.95   0.310       55\n",
      "neutral                50.21   27.51   50.21   35.54   0.216      235\n",
      "optimism                4.92   30.00    4.92    8.45   0.108       61\n",
      "pride                  60.71   45.95   60.71   52.31   0.518       28\n",
      "realization            26.47   38.03   26.47   31.21   0.278      102\n",
      "remorse                10.00   28.57   10.00   14.81   0.163       20\n",
      "sadness                51.45   37.37   51.45   43.29   0.375      138\n",
      "surprise                2.78   50.00    2.78    5.26   0.114       36\n",
      "\n",
      "Overall accuracy: 31.57%\n",
      "Overall MCC: 0.246\n",
      "\n",
      "========== Fold 9/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done. Best ValLoss=1.2163 | Val Node Acc=36.8% | Val Graph Acc=100.0%\n",
      "Saved best model for fold 9: gnn_multitask_best_fold9.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              6.12   20.00    6.12    9.38   0.095       49\n",
      "amusement              33.33   21.05   33.33   25.81   0.258       12\n",
      "anger                   0.00    0.00    0.00    0.00  -0.001        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               54.02   28.66   54.02   37.45   0.288      174\n",
      "caring                  3.03  100.00    3.03    5.88   0.172       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity               0.00    0.00    0.00    0.00   0.000        6\n",
      "desire                  8.91   45.00    8.91   14.88   0.179      101\n",
      "disappointment         60.00   35.51   60.00   44.62   0.390      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment          50.00   20.00   50.00   28.57   0.315        2\n",
      "excitement             30.00   29.03   30.00   29.51   0.281       30\n",
      "fear                   59.68   31.62   59.68   41.34   0.403       62\n",
      "gratitude              82.14   33.82   82.14   47.92   0.515       28\n",
      "joy                    20.00   38.00   20.00   26.21   0.243       95\n",
      "love                   33.33   71.43   33.33   45.45   0.472       75\n",
      "nervousness             5.45   75.00    5.45   10.17   0.197       55\n",
      "neutral                38.30   32.37   38.30   35.09   0.226      235\n",
      "optimism               18.03   39.29   18.03   24.72   0.247       61\n",
      "pride                  71.43   26.67   71.43   38.83   0.421       28\n",
      "realization            29.41   32.26   29.41   30.77   0.262      102\n",
      "remorse                10.00   20.00   10.00   13.33   0.134       20\n",
      "sadness                42.75   41.26   42.75   41.99   0.363      138\n",
      "surprise                8.33   60.00    8.33   14.63   0.218       36\n",
      "\n",
      "Overall accuracy: 33.74%\n",
      "Overall MCC: 0.279\n",
      "\n",
      "========== Fold 10/10 ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 48\n",
      "Fold 10 done. Best ValLoss=3.3545 | Val Node Acc=23.3% | Val Graph Acc=81.2%\n",
      "Saved best model for fold 10: gnn_multitask_best_fold10.pth\n",
      "\n",
      "Per-emotion metrics on TEST set:\n",
      "Emotion                  Acc    Prec     Rec      F1     MCC  Support\n",
      "admiration              0.00    0.00    0.00    0.00   0.000       49\n",
      "amusement               0.00    0.00    0.00    0.00   0.000       12\n",
      "anger                   0.00    0.00    0.00    0.00   0.000        5\n",
      "annoyance               0.00    0.00    0.00    0.00   0.000       42\n",
      "approval               56.90   20.84   56.90   30.51   0.205      174\n",
      "caring                  0.00    0.00    0.00    0.00   0.000       33\n",
      "confusion               0.00    0.00    0.00    0.00   0.000       30\n",
      "curiosity               0.00    0.00    0.00    0.00   0.000        6\n",
      "desire                  0.00    0.00    0.00    0.00   0.000      101\n",
      "disappointment         83.45   21.27   83.45   33.89   0.313      145\n",
      "disapproval             0.00    0.00    0.00    0.00   0.000        5\n",
      "disgust                 0.00    0.00    0.00    0.00   0.000        2\n",
      "embarrassment           0.00    0.00    0.00    0.00   0.000        2\n",
      "excitement              0.00    0.00    0.00    0.00   0.000       30\n",
      "fear                    0.00    0.00    0.00    0.00   0.000       62\n",
      "gratitude               0.00    0.00    0.00    0.00   0.000       28\n",
      "joy                     0.00    0.00    0.00    0.00   0.000       95\n",
      "love                    0.00    0.00    0.00    0.00   0.000       75\n",
      "nervousness             0.00    0.00    0.00    0.00   0.000       55\n",
      "neutral                47.23   21.06   47.23   29.13   0.122      235\n",
      "optimism                0.00    0.00    0.00    0.00   0.000       61\n",
      "pride                   0.00    0.00    0.00    0.00   0.000       28\n",
      "realization             0.00    0.00    0.00    0.00   0.000      102\n",
      "remorse                 0.00    0.00    0.00    0.00   0.000       20\n",
      "sadness                 0.00    0.00    0.00    0.00   0.000      138\n",
      "surprise                0.00    0.00    0.00    0.00   0.000       36\n",
      "\n",
      "Overall accuracy: 21.07%\n",
      "Overall MCC: 0.119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_graphs, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "fold_results = []\n",
    "\n",
    "for fold_id, (train_sids, val_sids) in enumerate(cv_folds, start=1):\n",
    "    print(f\"\\n========== Fold {fold_id}/{len(cv_folds)} ==========\")\n",
    "    train_loader, val_loader = make_loaders_from_session_ids(train_sids, val_sids, batch_size=BATCH_SIZE)\n",
    "\n",
    "    node_w, graph_w = compute_class_weights_for_fold(\n",
    "        train_sids, num_node_classes, num_graph_classes, min_w=0.5, max_w=2.0\n",
    "    )\n",
    "\n",
    "\n",
    "    model = GATv2MultiTask_Small(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dim=HIDDEN,\n",
    "        num_node_classes=num_node_classes,\n",
    "        num_graph_classes=num_graph_classes,\n",
    "        heads=HEADS,\n",
    "        dropout=DROPOUT\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, model.parameters()),\n",
    "        lr=LR, weight_decay=WEIGHT_DECAY\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode=\"min\", factor=0.5, patience=10, verbose=False\n",
    "    )\n",
    "\n",
    "    loss_node_fn  = nn.CrossEntropyLoss(weight=node_w, label_smoothing=0.05)\n",
    "    loss_graph_fn = nn.CrossEntropyLoss(weight=graph_w)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    patience_ctr = 0\n",
    "    val_metrics = {\"loss\": float(\"inf\"), \"node_acc\": 0, \"graph_acc\": 0, \"node_f1\": 0, \"graph_f1\": 0}\n",
    "\n",
    "    pbar = tqdm(range(1, EPOCHS + 1), desc=f\"Fold {fold_id}/{len(cv_folds)}\", leave=False, ncols=120)\n",
    "\n",
    "    start_epoch = int(ANNEAL_START_FRAC * EPOCHS)\n",
    "\n",
    "    for epoch in pbar:\n",
    "        if epoch < start_epoch:\n",
    "            lambda_node  = LAMBDA_NODE_START\n",
    "        else:\n",
    "            if EPOCHS == start_epoch:\n",
    "                t = 1.0\n",
    "            else:\n",
    "                t = (epoch - start_epoch) / max(1, (EPOCHS - start_epoch))\n",
    "            if ANNEAL_STRATEGY == \"cosine\":\n",
    "                w = 0.5 * (1 + math.cos(math.pi * t))\n",
    "                lambda_node = LAMBDA_NODE_END + (LAMBDA_NODE_START - LAMBDA_NODE_END) * w\n",
    "            else:\n",
    "                lambda_node = LAMBDA_NODE_START + (LAMBDA_NODE_END - LAMBDA_NODE_START) * t\n",
    "\n",
    "        lambda_graph = LAMBDA_GRAPH\n",
    "\n",
    "        # --- training ---=================\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        all_node_preds, all_node_labels = [], []\n",
    "        all_graph_preds, all_graph_labels = [], []\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_in = maybe_augment_x(batch.x, sigma=0.01, p=0.5)\n",
    "            node_out, graph_out = model(x_in, batch.edge_index, batch.batch)\n",
    "\n",
    "            loss_n = loss_node_fn(node_out, batch.y)\n",
    "            loss_g = loss_graph_fn(graph_out, batch.graph_label)\n",
    "            loss = lambda_node * loss_n + lambda_graph * loss_g\n",
    "            loss.backward()\n",
    "\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += float(loss.item())\n",
    "            all_node_preds.extend(node_out.argmax(dim=1).detach().cpu().tolist())\n",
    "            all_node_labels.extend(batch.y.detach().cpu().tolist())\n",
    "            all_graph_preds.extend(graph_out.argmax(dim=1).detach().cpu().tolist())\n",
    "            all_graph_labels.extend(batch.graph_label.detach().cpu().tolist())\n",
    "\n",
    "        avg_train_loss = total_train_loss / max(1, len(train_loader))\n",
    "        train_node_acc = accuracy_score(all_node_labels, all_node_preds) if all_node_labels else 0.0\n",
    "        train_graph_acc = accuracy_score(all_graph_labels, all_graph_preds) if all_graph_labels else 0.0\n",
    "\n",
    "        # --- validation ------------------- ---\n",
    "        val_metrics = evaluate_epoch(model, val_loader, loss_node_fn, loss_graph_fn,\n",
    "                                     lambda_node=lambda_node, lambda_graph=lambda_graph)\n",
    "        scheduler.step(val_metrics[\"loss\"])\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            \"λn\": f\"{lambda_node:.2f}\",\n",
    "            \"TL\": f\"{avg_train_loss:.3f}\",\n",
    "            \"VL\": f\"{val_metrics['loss']:.3f}\",\n",
    "            \"Tn\": f\"{train_node_acc*100:.1f}\",\n",
    "            \"Vn\": f\"{val_metrics['node_acc']*100:.1f}\",\n",
    "            \"Tg\": f\"{train_graph_acc*100:.1f}\",\n",
    "            \"Vg\": f\"{val_metrics['graph_acc']*100:.1f}\",\n",
    "        })\n",
    "\n",
    "        if val_metrics[\"loss\"] < best_val_loss - 1e-6:\n",
    "            best_val_loss = val_metrics[\"loss\"]\n",
    "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "            patience_ctr = 0\n",
    "        else:\n",
    "            patience_ctr += 1\n",
    "            if patience_ctr >= PATIENCE:\n",
    "                pbar.close()\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    pbar.close()\n",
    "    print(f\"Fold {fold_id} done. Best ValLoss={best_val_loss:.4f} | \"\n",
    "          f\"Val Node Acc={val_metrics['node_acc']*100:.1f}% | Val Graph Acc={val_metrics['graph_acc']*100:.1f}%\")\n",
    "\n",
    "    model_path = f\"gnn_multitask_best_fold{fold_id}.pth\"\n",
    "    torch.save(best_state, model_path)\n",
    "    print(f\"Saved best model for fold {fold_id}: {model_path}\")\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    model.to(device)\n",
    "\n",
    "    test_lambda_node = LAMBDA_NODE_END\n",
    "    test_lambda_graph = LAMBDA_GRAPH\n",
    "\n",
    "    test_metrics = evaluate_epoch(model, test_loader, loss_node_fn, loss_graph_fn,\n",
    "                                  lambda_node=test_lambda_node, lambda_graph=test_lambda_graph)\n",
    "\n",
    "    all_node_labels = np.array(test_metrics[\"node_labels\"])\n",
    "    all_node_preds  = np.array(test_metrics[\"node_preds\"])\n",
    "\n",
    "    mcc_overall = matthews_corrcoef(all_node_labels, all_node_preds) if len(np.unique(all_node_labels)) > 1 else 0.0\n",
    "    overall_acc = accuracy_score(all_node_labels, all_node_preds)\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        all_node_labels, all_node_preds, labels=range(num_node_classes), zero_division=0\n",
    "    )\n",
    "\n",
    "    print(\"\\nPer-emotion metrics on TEST set:\")\n",
    "    print(f\"{'Emotion':<20} {'Acc':>7} {'Prec':>7} {'Rec':>7} {'F1':>7} {'MCC':>7} {'Support':>8}\")\n",
    "    for idx in range(num_node_classes):\n",
    "        cls_name = emotion_encoder.classes_[idx]\n",
    "        cls_support = int(support[idx])\n",
    "        cls_acc = (all_node_preds[all_node_labels == idx] == idx).mean() if cls_support > 0 else 0.0\n",
    "        if cls_support > 0:\n",
    "            cls_mcc = matthews_corrcoef((all_node_labels == idx).astype(int),\n",
    "                                        (all_node_preds == idx).astype(int))\n",
    "        else:\n",
    "            cls_mcc = 0.0\n",
    "        print(f\"{cls_name:<20} {cls_acc*100:7.2f} {precision[idx]*100:7.2f} \"\n",
    "              f\"{recall[idx]*100:7.2f} {f1[idx]*100:7.2f} {cls_mcc:7.3f} {cls_support:8d}\")\n",
    "\n",
    "    print(f\"\\nOverall accuracy: {overall_acc*100:.2f}%\")\n",
    "    print(f\"Overall MCC: {mcc_overall:.3f}\")\n",
    "\n",
    "    fold_results.append({\n",
    "        \"fold\": fold_id,\n",
    "        \"val_loss\": round(best_val_loss, 4),\n",
    "        \"val_node_acc\": round(val_metrics[\"node_acc\"], 4),\n",
    "        \"val_node_f1\": round(val_metrics[\"node_f1\"], 4),\n",
    "        \"val_graph_acc\": round(val_metrics[\"graph_acc\"], 4),\n",
    "        \"val_graph_f1\": round(val_metrics[\"graph_f1\"], 4),\n",
    "        \"test_node_acc\": round(overall_acc, 4),\n",
    "        \"test_node_f1\": round(f1.mean(), 4),\n",
    "        \"test_graph_acc\": round(accuracy_score(test_metrics[\"graph_labels\"], test_metrics[\"graph_preds\"]), 4) if test_metrics[\"graph_labels\"] else 0.0,\n",
    "        \"test_graph_f1\": round(f1_score(test_metrics[\"graph_labels\"], test_metrics[\"graph_preds\"], average=\"macro\", zero_division=0), 4) if test_metrics[\"graph_labels\"] else 0.0,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5449da5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-Fold Summary (best val + test) — last row is AVG\n",
      "fold val_node_acc val_node_f1 val_graph_acc val_graph_f1 test_node_acc test_node_f1 test_graph_acc test_graph_f1 val_loss\n",
      "   1         37.2        14.2         100.0        100.0          33.9         22.2           86.8          50.8    1.226\n",
      "   2         29.9         4.6          20.0         16.7           4.9          1.0           79.0          29.4    3.982\n",
      "   3         34.8        22.7         100.0        100.0          34.6         20.9           84.2          45.1    1.270\n",
      "   4         32.9        19.3         100.0        100.0          31.8         21.0           86.8          50.8    1.214\n",
      "   5         28.5         8.8          93.3         48.3          24.6          6.8           79.0          29.4    2.357\n",
      "   6         26.9         7.5          80.0         44.4          21.2          4.3           79.0          29.4    2.506\n",
      "   7         28.8        21.0         100.0        100.0          33.6         22.5           86.8          50.8    1.315\n",
      "   8         29.1        21.2         100.0        100.0          31.6         17.6           84.2          45.1    1.315\n",
      "   9         36.8        27.5         100.0        100.0          33.7         21.8           84.2          45.1    1.216\n",
      "  10         23.3         4.0          81.2         29.9          21.1          3.6           76.3          28.9    3.354\n",
      " AVG         30.8        15.1          87.5         73.9          27.1         14.2           82.6          40.5    1.976\n"
     ]
    }
   ],
   "source": [
    "#  Summaryyyy ---\n",
    "results_df = pd.DataFrame(fold_results)\n",
    "\n",
    "if results_df.empty:\n",
    "    print(\"No fold results to display.\")\n",
    "else:\n",
    "    col_order = [\n",
    "        \"fold\",\n",
    "        \"val_node_acc\", \"val_node_f1\", \"val_graph_acc\", \"val_graph_f1\",\n",
    "        \"test_node_acc\", \"test_node_f1\", \"test_graph_acc\", \"test_graph_f1\",\n",
    "        \"val_loss\"\n",
    "    ]\n",
    "    cols = [c for c in col_order if c in results_df.columns]\n",
    "    df_summary = results_df[cols].copy()\n",
    "\n",
    "    avg_row = df_summary.drop(columns=[\"fold\"], errors=\"ignore\").mean(numeric_only=True).to_dict()\n",
    "    avg_row[\"fold\"] = \"AVG\"\n",
    "    df_summary = pd.concat([df_summary, pd.DataFrame([avg_row])], ignore_index=True)\n",
    "\n",
    "    pct_cols = [c for c in df_summary.columns if c.endswith(\"_acc\") or c.endswith(\"_f1\")]\n",
    "    df_num = df_summary.copy()\n",
    "    for c in pct_cols:\n",
    "        df_num[c] = pd.to_numeric(df_num[c], errors=\"coerce\") * 100.0\n",
    "    if \"val_loss\" in df_num.columns:\n",
    "        df_num[\"val_loss\"] = pd.to_numeric(df_num[\"val_loss\"], errors=\"coerce\")\n",
    "\n",
    "    with pd.option_context('display.max_columns', None, 'display.width', 120):\n",
    "        print(\"\\nK-Fold Summary (best val + test) — last row is AVG\")\n",
    "        print(df_num.to_string(index=False, formatters={**{c: \"{:.1f}\".format for c in pct_cols},\n",
    "                                                        **({\"val_loss\": \"{:.3f}\".format} if \"val_loss\" in df_num.columns else {})}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73614ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
